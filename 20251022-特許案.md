【発明の名称】

通信帯域・GPU・CPUを統合制御する合成データ生成スケジューリング装置、方法およびプログラム

【背景技術】（要旨レベル）

合成データ生成サーバでは、入力データの取得および生成結果の送信に伴うネットワークI/Oがボトルネック化し、GPUやCPUのアイドル時間が発生する。従来のスケジューリングは計算資源（GPU/CPU）中心であり、通信帯域を同時最適化できず、パイプライン全体のクリティカルパス短縮に限界があった。

【課題】

外部ストレージ／クラウドとのデータ転送（ダウンロード／アップロード）を伴う合成データ生成パイプラインにおいて、通信帯域状況・GPUのVRAM等使用状況・CPU実行状況を同時に考慮しつつ、タスク依存関係に基づく動的再スケジューリングにより、全体のクリティカルパスを短縮し、スループットを最大化する。

【解決手段】（要旨）

本装置は、(i) ネットワークI/O監視部（帯域使用率、遅延、スループットを取得）、(ii) タスク依存グラフ管理部（通信ノード・GPUノード・CPUノードを含む拡張DAGを保持）、(iii) 実行時間予測部（通信・GPU・CPUの処理時間を学習／統計で推定）、(iv) 統合スケジューラ（予測と実測を用いてキュー順序・並列度をリアルタイム更新）を備える。
スケジューラは、通信帯域の混雑やGPUのVRAM不足またはI/O待ち検出時に、通信完了待ちのないCPUタスクの割込投入、事前プリフェッチ／結果アップロードの前倒し、データ圧縮／解凍と計算のオーバーラップ、および通信ノードを含むクリティカルパス最短化を行う。これにより、GPU/CPU/ネットワークの三層を統合した動的パイプライン最適化が実現する。

【効果】

(1) 通信待機に起因するGPUアイドルを大幅削減
(2) 通信・計算・（任意で）圧縮処理の同時並列化により全体スループット向上
(3) クラウド／オンプレを問わず、帯域変動に適応
(4) 合成データ生成パイプライン（レンダリング、アノテーション、転送、学習連携）でクリティカルパス短縮を実現

【請求項】（正式文体・3項）

【請求項1】
外部ネットワークを介して入力データを取得し、生成された出力データを送信して合成データ生成処理を行うサーバシステムにおいて、
前記外部ネットワークの帯域使用状況または遅延に関する少なくとも一つの通信メトリクスを取得するネットワークI/O監視部と、
通信処理、GPUを用いる処理およびCPUを用いる処理を各ノードとして含むタスク依存グラフを保持するタスク依存グラフ管理部と、
前記通信処理、前記GPUを用いる処理および前記CPUを用いる処理の各推定実行時間を、過去の実行ログまたは統計モデルに基づき推定する実行時間予測部と、
前記通信メトリクスおよび前記推定実行時間に基づいて前記タスク依存グラフのノードの実行順序または並列度を動的に更新し、前記GPUを用いる処理と前記CPUを用いる処理とのオーバーラップ実行および前記通信処理の事前プリフェッチまたは結果送信の前倒しを制御する統合スケジューラと、
を備え、
前記統合スケジューラは、前記通信処理の進行状況および前記GPUのI/O待機イベントに応答して前記タスク依存グラフを再構成し、通信処理ノードを含むクリティカルパスの長さが短縮されるように前記ノードの実行を制御することを特徴とする、スケジューリング装置。

【請求項2】
請求項1に記載のスケジューリング装置において、
前記統合スケジューラは、前記外部ネットワークの帯域が所定閾値以下であるとき、前記GPUを用いない圧縮処理またはメタデータ生成処理を優先的に割当てるとともに、前記帯域が所定閾値を超えた時点で前記通信処理ノードを起動し、これと前記GPUを用いる処理とをオーバーラップさせることを特徴とする、スケジューリング装置。

【請求項3】
請求項1または2に記載のスケジューリング装置において、
前記実行時間予測部は、前記通信処理、前記GPUを用いる処理および前記CPUを用いる処理の実測ログに基づいて学習された機械学習モデルにより各推定実行時間を出力し、
前記統合スケジューラは、当該推定実行時間と前記通信メトリクスとに基づき、前記タスク依存グラフのノードの実行順序、リソース割当および並列度を逐次更新することを特徴とする、スケジューリング装置。
